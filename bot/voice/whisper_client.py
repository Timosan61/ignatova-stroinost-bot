"""
Whisper Client - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI Whisper API –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è ignatova-stroinost-bot
"""

import os
import logging
from typing import Optional, Dict, Any
from pathlib import Path

import openai
from openai import AsyncOpenAI

from .config import (
    WHISPER_MODEL, WHISPER_RESPONSE_FORMAT, WHISPER_LANGUAGE,
    WHISPER_TIMEOUT_SECONDS, SUPPORTED_AUDIO_FORMATS
)

logger = logging.getLogger(__name__)


class WhisperTranscriber:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ OpenAI Whisper API"""
    
    def __init__(self, api_key: str):
        if not api_key:
            raise ValueError("OpenAI API key is required for Whisper transcription")
        
        self.client = AsyncOpenAI(
            api_key=api_key,
            timeout=WHISPER_TIMEOUT_SECONDS
        )
    
    async def transcribe(self, audio_file_path: str, language: Optional[str] = None) -> Dict[str, Any]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –≤ —Ç–µ–∫—Å—Ç
        
        Args:
            audio_file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            language: –Ø–∑—ã–∫ –∞—É–¥–∏–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä—É—Å—Å–∫–∏–π)
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
            validation_result = self.validate_audio_file(audio_file_path)
            if not validation_result["valid"]:
                logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {validation_result['error']}")
                return {
                    "success": False,
                    "error": validation_result["error"],
                    "text": None
                }
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Whisper
            transcription_params = {
                "model": WHISPER_MODEL,
                "response_format": WHISPER_RESPONSE_FORMAT
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —è–∑—ã–∫ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            target_language = language or WHISPER_LANGUAGE
            if target_language:
                transcription_params["language"] = target_language
            
            logger.info(f"üé§ –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Ñ–∞–π–ª–∞: {audio_file_path}")
            logger.debug(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Whisper: {transcription_params}")
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ Whisper
            with open(audio_file_path, "rb") as audio_file:
                transcript = await self.client.audio.transcriptions.create(
                    file=audio_file,
                    **transcription_params
                )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if isinstance(transcript, str):
                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                transcribed_text = transcript.strip()
            else:
                # JSON –æ—Ç–≤–µ—Ç
                transcribed_text = getattr(transcript, 'text', '').strip()
            
            if transcribed_text:
                logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {len(transcribed_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                logger.debug(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {transcribed_text[:100]}...")
                
                return {
                    "success": True,
                    "text": transcribed_text,
                    "language": target_language,
                    "file_path": audio_file_path,
                    "char_count": len(transcribed_text)
                }
            else:
                logger.warning("‚ö†Ô∏è Whisper –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return {
                    "success": False,
                    "error": "Empty transcription result",
                    "text": None
                }
                
        except openai.APIError as e:
            logger.error(f"‚ùå OpenAI API –æ—à–∏–±–∫–∞: {e}")
            return {
                "success": False,
                "error": f"OpenAI API error: {str(e)}",
                "text": None
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return {
                "success": False,
                "error": f"Transcription error: {str(e)}",
                "text": None
            }
    
    def validate_audio_file(self, file_path: str) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Whisper
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {"valid": bool, "error": str}
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not os.path.exists(file_path):
                return {"valid": False, "error": f"File not found: {file_path}"}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ñ–∞–π–ª
            if not os.path.isfile(file_path):
                return {"valid": False, "error": f"Path is not a file: {file_path}"}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                return {"valid": False, "error": "File is empty"}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            file_extension = Path(file_path).suffix.lower().lstrip('.')
            if file_extension not in SUPPORTED_AUDIO_FORMATS:
                return {
                    "valid": False, 
                    "error": f"Unsupported format: {file_extension}. Supported: {SUPPORTED_AUDIO_FORMATS}"
                }
            
            logger.debug(f"‚úÖ –§–∞–π–ª –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: {file_path} ({file_size} bytes, .{file_extension})")
            return {"valid": True, "error": None}
            
        except Exception as e:
            return {"valid": False, "error": f"Validation error: {str(e)}"}
    
    def get_supported_formats(self) -> list:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        return SUPPORTED_AUDIO_FORMATS.copy()
    
    async def test_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ API –∫–ª—é—á–∞
            models = await self.client.models.list()
            if models:
                logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API —É—Å–ø–µ—à–Ω–æ")
                return True
            else:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
                return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI API: {e}")
            return False