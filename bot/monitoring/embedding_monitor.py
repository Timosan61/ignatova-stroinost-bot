"""
–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ embeddings
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç latency, tokens, costs –¥–ª—è OpenAI Embeddings API
"""

import time
import logging
from dataclasses import dataclass, field
from typing import List, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class EmbeddingMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ embeddings"""

    total_calls: int = 0
    total_tokens: int = 0
    total_cost_usd: float = 0.0
    latencies_ms: List[float] = field(default_factory=list)
    errors: int = 0
    start_time: float = field(default_factory=time.time)

    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (OpenAI text-embedding-3-small)
    COST_PER_1K_TOKENS: float = 0.00002  # $0.00002 / 1K tokens

    def add_call(self, tokens: int, latency_ms: float, error: bool = False):
        """–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É –≤—ã–∑–æ–≤–∞ embeddings API"""
        self.total_calls += 1
        self.total_tokens += tokens
        self.latencies_ms.append(latency_ms)

        if error:
            self.errors += 1
        else:
            # –°—Ç–æ–∏–º–æ—Å—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
            cost = (tokens / 1000.0) * self.COST_PER_1K_TOKENS
            self.total_cost_usd += cost

    @property
    def avg_latency_ms(self) -> float:
        """–°—Ä–µ–¥–Ω—è—è latency –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö"""
        if not self.latencies_ms:
            return 0.0
        return sum(self.latencies_ms) / len(self.latencies_ms)

    @property
    def p95_latency_ms(self) -> float:
        """95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å latency (95% –≤—ã–∑–æ–≤–æ–≤ –±—ã—Å—Ç—Ä–µ–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)"""
        if not self.latencies_ms:
            return 0.0
        sorted_latencies = sorted(self.latencies_ms)
        index = int(len(sorted_latencies) * 0.95)
        return sorted_latencies[index] if index < len(sorted_latencies) else sorted_latencies[-1]

    @property
    def p99_latency_ms(self) -> float:
        """99-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å latency (99% –≤—ã–∑–æ–≤–æ–≤ –±—ã—Å—Ç—Ä–µ–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)"""
        if not self.latencies_ms:
            return 0.0
        sorted_latencies = sorted(self.latencies_ms)
        index = int(len(sorted_latencies) * 0.99)
        return sorted_latencies[index] if index < len(sorted_latencies) else sorted_latencies[-1]

    @property
    def max_latency_ms(self) -> float:
        """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è latency"""
        return max(self.latencies_ms) if self.latencies_ms else 0.0

    @property
    def min_latency_ms(self) -> float:
        """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è latency"""
        return min(self.latencies_ms) if self.latencies_ms else 0.0

    @property
    def uptime_seconds(self) -> float:
        """–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        return time.time() - self.start_time

    @property
    def error_rate(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ (0-100)"""
        if self.total_calls == 0:
            return 0.0
        return (self.errors / self.total_calls) * 100.0

    def get_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–¥–∫—É –º–µ—Ç—Ä–∏–∫ –¥–ª—è API"""
        return {
            "total_calls": self.total_calls,
            "total_tokens": self.total_tokens,
            "total_cost_usd": round(self.total_cost_usd, 6),
            "errors": self.errors,
            "error_rate_percent": round(self.error_rate, 2),
            "latency": {
                "avg_ms": round(self.avg_latency_ms, 2),
                "p95_ms": round(self.p95_latency_ms, 2),
                "p99_ms": round(self.p99_latency_ms, 2),
                "min_ms": round(self.min_latency_ms, 2),
                "max_ms": round(self.max_latency_ms, 2)
            },
            "uptime_seconds": round(self.uptime_seconds, 1),
            "started_at": datetime.fromtimestamp(self.start_time).isoformat()
        }

    def reset(self):
        """–°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏"""
        self.total_calls = 0
        self.total_tokens = 0
        self.total_cost_usd = 0.0
        self.latencies_ms = []
        self.errors = 0
        self.start_time = time.time()
        logger.info("üîÑ –ú–µ—Ç—Ä–∏–∫–∏ embeddings —Å–±—Ä–æ—à–µ–Ω—ã")


# Singleton instance
_metrics_instance = None


def get_metrics() -> EmbeddingMetrics:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ—Ç—Ä–∏–∫"""
    global _metrics_instance
    if _metrics_instance is None:
        _metrics_instance = EmbeddingMetrics()
        logger.info("üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ embeddings")
    return _metrics_instance


def track_embedding_call(func):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—ã–∑–æ–≤–æ–≤ embeddings

    Usage:
        @track_embedding_call
        def generate_embedding(text: str) -> List[float]:
            ...
    """
    async def wrapper(*args, **kwargs):
        metrics = get_metrics()
        start_time = time.time()
        error_occurred = False

        try:
            result = await func(*args, **kwargs)
            return result
        except Exception as e:
            error_occurred = True
            raise e
        finally:
            latency_ms = (time.time() - start_time) * 1000

            # –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–º–µ—Ä–Ω–æ 1 —Ç–æ–∫–µ–Ω = 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ)
            # –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ –Ω—É–∂–µ–Ω tiktoken, –Ω–æ —ç—Ç–æ —É–≤–µ–ª–∏—á–∏—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            text = args[1] if len(args) > 1 else kwargs.get('text', '')
            estimated_tokens = len(str(text)) // 4

            metrics.add_call(
                tokens=estimated_tokens,
                latency_ms=latency_ms,
                error=error_occurred
            )

    return wrapper
