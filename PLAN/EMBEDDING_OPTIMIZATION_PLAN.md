# –ü–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏—è text-embedding-3-small –¥–ª—è systemd deployment

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 18 –Ω–æ—è–±—Ä—è 2025
**–°—Ç–∞—Ç—É—Å:** –í –ø–ª–∞–Ω–∞—Ö (–Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ)
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** HIGH
**–û–±—â–µ–µ –≤—Ä–µ–º—è:** 6-9 —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã

---

## üéØ –¶–µ–ª–∏ –∏ –º–æ—Ç–∏–≤–∞—Ü–∏—è

### –ü—Ä–æ–±–ª–µ–º—ã —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
1. **–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞:** –¢–æ–ª—å–∫–æ semantic search (–±–µ–∑ keyword matching)
2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** Minimal visibility –≤ production (–Ω–µ—Ç –º–µ—Ç—Ä–∏–∫ latency, tokens, costs)
3. **–°–∫–æ—Ä–æ—Å—Ç—å:** –ù–µ—Ç batch processing, –Ω–µ—Ç caching –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö queries, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

### –¶–µ–ª–∏ –ø–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏–π:
- ‚úÖ **–ö–∞—á–µ—Å—Ç–≤–æ:** +15-25% —Ç–æ—á–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ Hybrid Search (semantic + fulltext)
- ‚úÖ **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** Full visibility (latency, tokens, costs) –¥–ª—è production debugging
- ‚úÖ **–°–∫–æ—Ä–æ—Å—Ç—å:** 4-5x –±—ã—Å—Ç—Ä–µ–µ –º–∏–≥—Ä–∞—Ü–∏–∏, 127x –±—ã—Å—Ç—Ä–µ–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ queries, 2x –±—ã—Å—Ç—Ä–µ–µ multi-stage search

---

## üìã –≠—Ç–∞–ø—ã –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –≠—Ç–∞–ø 1: Hybrid Search –≤ Supabase
**–í—Ä–µ–º—è:** 2-3 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî• HIGH
**–≠—Ñ—Ñ–µ–∫—Ç:** +15-25% —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞

#### –ß—Ç–æ –¥–µ–ª–∞–µ–º:

**1.1. SQL Migration - Hybrid Search Function**

–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª: `migrations/supabase/hybrid_search.sql`

```sql
-- –§—É–Ω–∫—Ü–∏—è –¥–ª—è hybrid search (semantic + fulltext)
CREATE OR REPLACE FUNCTION match_documents_hybrid(
    query_embedding vector(1536),
    query_text text,
    entity_filter text DEFAULT NULL,
    match_threshold float DEFAULT 0.7,
    match_count int DEFAULT 10,
    semantic_weight float DEFAULT 0.7,
    fulltext_weight float DEFAULT 0.3
)
RETURNS TABLE (
    id uuid,
    content text,
    metadata jsonb,
    entity_type text,
    similarity float,
    fulltext_rank float,
    combined_score float
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    WITH semantic_results AS (
        -- Semantic search —á–µ—Ä–µ–∑ pgvector
        SELECT
            ck.id,
            ck.content,
            ck.metadata,
            ck.metadata->>'entity_type' as entity_type,
            1 - (ck.embedding <=> query_embedding) as similarity,
            0.0 as fulltext_rank
        FROM course_knowledge ck
        WHERE
            (entity_filter IS NULL OR ck.metadata->>'entity_type' = entity_filter)
            AND 1 - (ck.embedding <=> query_embedding) > match_threshold
        ORDER BY ck.embedding <=> query_embedding
        LIMIT match_count * 2
    ),
    fulltext_results AS (
        -- Fulltext search —á–µ—Ä–µ–∑ tsvector
        SELECT
            ck.id,
            ck.content,
            ck.metadata,
            ck.metadata->>'entity_type' as entity_type,
            0.0 as similarity,
            ts_rank(to_tsvector('russian', ck.content), plainto_tsquery('russian', query_text)) as fulltext_rank
        FROM course_knowledge ck
        WHERE
            (entity_filter IS NULL OR ck.metadata->>'entity_type' = entity_filter)
            AND to_tsvector('russian', ck.content) @@ plainto_tsquery('russian', query_text)
        ORDER BY fulltext_rank DESC
        LIMIT match_count * 2
    ),
    combined AS (
        -- –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å RRF (Reciprocal Rank Fusion)
        SELECT
            COALESCE(s.id, f.id) as id,
            COALESCE(s.content, f.content) as content,
            COALESCE(s.metadata, f.metadata) as metadata,
            COALESCE(s.entity_type, f.entity_type) as entity_type,
            COALESCE(s.similarity, 0.0) as similarity,
            COALESCE(f.fulltext_rank, 0.0) as fulltext_rank,
            (COALESCE(s.similarity, 0.0) * semantic_weight +
             COALESCE(f.fulltext_rank, 0.0) * fulltext_weight) as combined_score
        FROM semantic_results s
        FULL OUTER JOIN fulltext_results f ON s.id = f.id
    )
    SELECT * FROM combined
    ORDER BY combined_score DESC
    LIMIT match_count;
END;
$$;

-- –°–æ–∑–¥–∞—ë–º GIN –∏–Ω–¥–µ–∫—Å –¥–ª—è fulltext search
CREATE INDEX IF NOT EXISTS idx_course_knowledge_content_fulltext
ON course_knowledge USING GIN (to_tsvector('russian', content));
```

**1.2. –û–±–Ω–æ–≤–∏—Ç—å `bot/services/supabase_service.py`**

–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `hybrid_search()`:

```python
async def hybrid_search(
    self,
    query: str,
    entity_type: Optional[str] = None,
    limit: int = 10,
    semantic_weight: float = 0.7,
    fulltext_weight: float = 0.3
) -> List[Dict[str, Any]]:
    """
    Hybrid search: semantic + fulltext

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        entity_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É (lesson, correction, faq, question, brainwrite)
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        semantic_weight: –í–µ—Å semantic search (0-1)
        fulltext_weight: –í–µ—Å fulltext search (0-1)

    Returns:
        List —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å combined_score
    """
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding –¥–ª—è query
        query_embedding = self._generate_embedding(query)

        # –í—ã–∑—ã–≤–∞–µ–º hybrid search function
        response = await self.supabase.rpc(
            'match_documents_hybrid',
            {
                'query_embedding': query_embedding,
                'query_text': query,
                'entity_filter': entity_type,
                'match_threshold': 0.7,
                'match_count': limit,
                'semantic_weight': semantic_weight,
                'fulltext_weight': fulltext_weight
            }
        ).execute()

        results = []
        for item in response.data:
            results.append({
                'content': item['content'],
                'metadata': item['metadata'],
                'entity_type': item['entity_type'],
                'score': item['combined_score'],
                'semantic_score': item['similarity'],
                'fulltext_score': item['fulltext_rank'],
                'source': 'supabase_hybrid'
            })

        logger.info(f"‚úÖ Hybrid search: {len(results)} results, avg_score={sum(r['score'] for r in results)/len(results) if results else 0:.2f}")
        return results

    except Exception as e:
        logger.error(f"‚ùå Hybrid search failed: {e}")
        # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π semantic search
        return await self.search_semantic(query, entity_type, limit)
```

**1.3. –û–±–Ω–æ–≤–∏—Ç—å `bot/services/knowledge_search.py`**

–ó–∞–º–µ–Ω–∏—Ç—å `search_semantic()` –Ω–∞ `hybrid_search()` –≤ –º–µ—Ç–æ–¥–µ `_search_semantic()`:

```python
async def _search_semantic(self, query: str, limit: int) -> List[Dict]:
    """Multi-stage hybrid search —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏"""
    all_results = []

    # –≠–¢–ê–ü 1: Lessons (–ü–†–ò–û–†–ò–¢–ï–¢ 1) - boost 1.5x
    if self.use_supabase and self.supabase_service:
        lesson_results = await self.supabase_service.hybrid_search(
            query=query,
            entity_type="lesson",
            limit=limit,
            semantic_weight=0.7,
            fulltext_weight=0.3
        )
        for r in lesson_results:
            r['score'] = r['score'] * 1.5  # BOOST!
            all_results.append(r)

    # –≠–¢–ê–ü 2: Corrections (–ü–†–ò–û–†–ò–¢–ï–¢ 2) - boost 1.2x
    if len(all_results) < limit:
        correction_results = await self.supabase_service.hybrid_search(
            query=query,
            entity_type="correction",
            limit=limit,
            semantic_weight=0.7,
            fulltext_weight=0.3
        )
        for r in correction_results:
            r['score'] = r['score'] * 1.2
            all_results.append(r)

    # –≠–¢–ê–ü 3: FAQ (–ü–†–ò–û–†–ò–¢–ï–¢ 3) - no boost
    if len(all_results) < limit:
        faq_results = await self.supabase_service.hybrid_search(
            query=query,
            entity_type="faq",
            limit=limit
        )
        all_results.extend(faq_results)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ boosted score
    all_results.sort(key=lambda x: x['score'], reverse=True)
    return all_results[:limit]
```

---

### –≠—Ç–∞–ø 2: Comprehensive Monitoring
**–í—Ä–µ–º—è:** 1-2 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî• HIGH
**–≠—Ñ—Ñ–µ–∫—Ç:** Full visibility –≤ production

#### –ß—Ç–æ –¥–µ–ª–∞–µ–º:

**2.1. –°–æ–∑–¥–∞—Ç—å `bot/monitoring/embedding_monitor.py`**

```python
"""
Monitoring –∏ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è embeddings (OpenAI text-embedding-3-small)
"""
import time
import logging
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import json

logger = logging.getLogger(__name__)

@dataclass
class EmbeddingMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è tracking embeddings"""

    # Counters
    total_calls: int = 0
    total_tokens: int = 0
    total_cost_usd: float = 0.0

    # Latency tracking
    latencies: List[float] = field(default_factory=list)

    # Errors
    errors: int = 0

    # Session info
    session_start: datetime = field(default_factory=datetime.now)

    def add_call(self, tokens: int, latency_ms: float, cost_usd: float):
        """–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –æ–¥–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞"""
        self.total_calls += 1
        self.total_tokens += tokens
        self.total_cost_usd += cost_usd
        self.latencies.append(latency_ms)

        # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –≤—ã–∑–æ–≤
        logger.info(
            f"‚è±Ô∏è OpenAI embedding: {latency_ms:.1f}ms | "
            f"tokens={tokens} | "
            f"cost=${cost_usd:.7f} | "
            f"model=text-embedding-3-small"
        )

    def add_error(self):
        """–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É"""
        self.errors += 1

    @property
    def avg_latency_ms(self) -> float:
        """–°—Ä–µ–¥–Ω—è—è latency –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö"""
        return sum(self.latencies) / len(self.latencies) if self.latencies else 0.0

    @property
    def p95_latency_ms(self) -> float:
        """95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å latency"""
        if not self.latencies:
            return 0.0
        sorted_latencies = sorted(self.latencies)
        idx = int(len(sorted_latencies) * 0.95)
        return sorted_latencies[idx]

    @property
    def session_duration_minutes(self) -> float:
        """–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö"""
        return (datetime.now() - self.session_start).total_seconds() / 60

    def summary(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å summary —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        return {
            "total_calls": self.total_calls,
            "total_tokens": self.total_tokens,
            "total_cost_usd": round(self.total_cost_usd, 6),
            "avg_latency_ms": round(self.avg_latency_ms, 1),
            "p95_latency_ms": round(self.p95_latency_ms, 1),
            "errors": self.errors,
            "session_duration_minutes": round(self.session_duration_minutes, 1),
            "calls_per_minute": round(self.total_calls / self.session_duration_minutes, 2) if self.session_duration_minutes > 0 else 0,
            "avg_tokens_per_call": round(self.total_tokens / self.total_calls, 1) if self.total_calls > 0 else 0
        }

    def log_summary(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å summary"""
        summary = self.summary()
        logger.info(
            f"\nüìä Embedding Session Stats:\n"
            f"  Calls: {summary['total_calls']:,}\n"
            f"  Tokens: {summary['total_tokens']:,}\n"
            f"  Cost: ${summary['total_cost_usd']:.6f}\n"
            f"  Avg Latency: {summary['avg_latency_ms']}ms\n"
            f"  P95 Latency: {summary['p95_latency_ms']}ms\n"
            f"  Errors: {summary['errors']}\n"
            f"  Duration: {summary['session_duration_minutes']} min\n"
            f"  Rate: {summary['calls_per_minute']} calls/min"
        )

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π singleton –¥–ª—è –º–µ—Ç—Ä–∏–∫
_global_metrics = EmbeddingMetrics()

def get_metrics() -> EmbeddingMetrics:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
    return _global_metrics

def reset_metrics():
    """–°–±—Ä–æ—Å–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)"""
    global _global_metrics
    _global_metrics = EmbeddingMetrics()
```

**2.2. –û–±–Ω–æ–≤–∏—Ç—å `bot/services/supabase_service.py`**

–î–æ–±–∞–≤–∏—Ç—å monitoring –≤ `_generate_embedding()`:

```python
from bot.monitoring.embedding_monitor import get_metrics
import time

def _generate_embedding(self, text: str) -> List[float]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding —á–µ—Ä–µ–∑ OpenAI API —Å monitoring"""
    try:
        start_time = time.time()

        response = self.openai_client.embeddings.create(
            input=text,
            model=self.embedding_model
        )

        latency_ms = (time.time() - start_time) * 1000
        tokens = response.usage.total_tokens

        # –°—Ç–æ–∏–º–æ—Å—Ç—å text-embedding-3-small: $0.00002 –∑–∞ 1K tokens
        cost_usd = (tokens / 1000) * 0.00002

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = get_metrics()
        metrics.add_call(tokens=tokens, latency_ms=latency_ms, cost_usd=cost_usd)

        return response.data[0].embedding

    except Exception as e:
        logger.error(f"‚ùå Embedding generation failed: {e}")
        get_metrics().add_error()
        raise
```

**2.3. –î–æ–±–∞–≤–∏—Ç—å API endpoint –≤ `main.py`**

```python
from bot.monitoring.embedding_monitor import get_metrics

@app.get("/api/admin/embedding/stats")
async def embedding_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É embeddings"""
    metrics = get_metrics()
    return {
        "status": "ok",
        "embedding_model": "text-embedding-3-small",
        "metrics": metrics.summary()
    }
```

**2.4. –î–æ–±–∞–≤–∏—Ç—å –≤ systemd service**

–û–±–Ω–æ–≤–∏—Ç—å `~/.config/systemd/user/ignatova-bot.service`:

```ini
[Service]
# Structured logging –¥–ª—è journalctl
Environment="PYTHONUNBUFFERED=1"
Environment="EMBEDDING_MONITORING_ENABLED=true"

# –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
ExecStartPost=/bin/sh -c 'while true; do sleep 300; curl -s http://localhost:8001/api/admin/embedding/stats | jq; done'
```

---

### –≠—Ç–∞–ø 3: Batch Processing
**–í—Ä–µ–º—è:** 1 —á–∞—Å
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° MEDIUM
**–≠—Ñ—Ñ–µ–∫—Ç:** –ú–∏–≥—Ä–∞—Ü–∏–∏ –≤ 4-5x –±—ã—Å—Ç—Ä–µ–µ

#### –ß—Ç–æ –¥–µ–ª–∞–µ–º:

**3.1. –û–±–Ω–æ–≤–∏—Ç—å `bot/services/supabase_service.py`**

–î–æ–±–∞–≤–∏—Ç—å batch –º–µ—Ç–æ–¥:

```python
def _generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
    """
    Batch –≥–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings (–¥–æ 100 —Ç–µ–∫—Å—Ç–æ–≤ –∑–∞ —Ä–∞–∑)

    –≠–∫–æ–Ω–æ–º–∏—è:
    - Network overhead: N requests ‚Üí 1 request
    - Cost: —Ç–æ –∂–µ —Å–∞–º–æ–µ (–ø–ª–∞—Ç–∏–º –∑–∞ —Ç–æ–∫–µ–Ω—ã)
    - Time: ~4-5x –±—ã—Å—Ç—Ä–µ–µ –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–π
    """
    try:
        start_time = time.time()

        response = self.openai_client.embeddings.create(
            input=texts,  # List[str] - –¥–æ 100 items
            model=self.embedding_model
        )

        latency_ms = (time.time() - start_time) * 1000
        tokens = response.usage.total_tokens
        cost_usd = (tokens / 1000) * 0.00002

        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è batch call
        metrics = get_metrics()
        metrics.add_call(tokens=tokens, latency_ms=latency_ms, cost_usd=cost_usd)

        logger.info(
            f"‚úÖ Batch embeddings: {len(texts)} texts, "
            f"{latency_ms:.0f}ms, "
            f"{tokens} tokens, "
            f"${cost_usd:.6f}"
        )

        return [item.embedding for item in response.data]

    except Exception as e:
        logger.error(f"‚ùå Batch embedding failed: {e}")
        get_metrics().add_error()
        raise
```

**3.2. –û–±–Ω–æ–≤–∏—Ç—å `scripts/migrate_to_supabase.py`**

–ó–∞–º–µ–Ω–∏—Ç—å —Ü–∏–∫–ª –Ω–∞ batch processing:

```python
# –î–û: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (22 –º–∏–Ω—É—Ç—ã –¥–ª—è 3,234 entities)
for entity in entities:
    embedding = self._generate_embedding(entity['content'])
    # ...
    time.sleep(0.05)  # Rate limiting

# –ü–û–°–õ–ï: –±–∞—Ç—á–∞–º–∏ (5 –º–∏–Ω—É—Ç –¥–ª—è 3,234 entities)
BATCH_SIZE = 100  # OpenAI limit

for i in range(0, len(entities), BATCH_SIZE):
    batch = entities[i:i+BATCH_SIZE]
    texts = [e['content'] for e in batch]

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º batch embeddings
    embeddings = self._generate_embeddings_batch(texts)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Supabase
    for entity, embedding in zip(batch, embeddings):
        await self.supabase.table('course_knowledge').insert({
            'content': entity['content'],
            'metadata': entity['metadata'],
            'embedding': embedding
        }).execute()

    # Rate limiting –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
    time.sleep(0.5)  # 500ms –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
```

---

### –≠—Ç–∞–ø 4: Query Caching
**–í—Ä–µ–º—è:** 1-2 —á–∞—Å–∞
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° MEDIUM
**–≠—Ñ—Ñ–µ–∫—Ç:** –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ queries 127x –±—ã—Å—Ç—Ä–µ–µ

#### –ß—Ç–æ –¥–µ–ª–∞–µ–º:

**4.1. –°–æ–∑–¥–∞—Ç—å `bot/cache/embedding_cache.py`**

```python
"""
LRU Cache –¥–ª—è embeddings queries
"""
from functools import lru_cache
from typing import List, Optional
import hashlib
import time
import logging

logger = logging.getLogger(__name__)

class EmbeddingCache:
    """
    In-memory LRU cache –¥–ª—è embeddings

    –ö—ç—à–∏—Ä—É–µ–º –ø–∞—Ä—ã (query_text -> embedding_vector)
    TTL: 1 —á–∞—Å (3600 —Å–µ–∫—É–Ω–¥)
    """

    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.cache = {}  # {query_hash: (embedding, timestamp)}
        self.hits = 0
        self.misses = 0

    def _get_hash(self, text: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å hash –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        return hashlib.sha256(text.encode()).hexdigest()[:16]

    def get(self, text: str) -> Optional[List[float]]:
        """–ü–æ–ª—É—á–∏—Ç—å embedding –∏–∑ cache"""
        key = self._get_hash(text)

        if key in self.cache:
            embedding, timestamp = self.cache[key]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            if time.time() - timestamp < self.ttl_seconds:
                self.hits += 1
                logger.debug(f"‚úÖ Cache HIT: {text[:50]}...")
                return embedding
            else:
                # Expired
                del self.cache[key]
                logger.debug(f"‚è∞ Cache EXPIRED: {text[:50]}...")

        self.misses += 1
        logger.debug(f"‚ùå Cache MISS: {text[:50]}...")
        return None

    def set(self, text: str, embedding: List[float]):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å embedding –≤ cache"""
        key = self._get_hash(text)

        # LRU eviction –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç
        if len(self.cache) >= self.max_size:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π
            oldest_key = min(self.cache.items(), key=lambda x: x[1][1])[0]
            del self.cache[oldest_key]
            logger.debug(f"üóëÔ∏è Cache EVICT: {oldest_key}")

        self.cache[key] = (embedding, time.time())
        logger.debug(f"üíæ Cache SET: {text[:50]}...")

    @property
    def hit_rate(self) -> float:
        """Cache hit rate (0-1)"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0

    def stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ cache"""
        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": round(self.hit_rate * 100, 1),
            "ttl_seconds": self.ttl_seconds
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π singleton
_global_cache = None

def get_cache() -> EmbeddingCache:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π cache"""
    global _global_cache
    if _global_cache is None:
        _global_cache = EmbeddingCache(max_size=1000, ttl_seconds=3600)
    return _global_cache
```

**4.2. –û–±–Ω–æ–≤–∏—Ç—å `bot/services/supabase_service.py`**

–î–æ–±–∞–≤–∏—Ç—å caching –≤ `_generate_embedding()`:

```python
from bot.cache.embedding_cache import get_cache

def _generate_embedding(self, text: str) -> List[float]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding —Å caching"""
    cache = get_cache()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º cache
    cached_embedding = cache.get(text)
    if cached_embedding is not None:
        return cached_embedding

    # Cache miss - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ OpenAI
    try:
        start_time = time.time()

        response = self.openai_client.embeddings.create(
            input=text,
            model=self.embedding_model
        )

        latency_ms = (time.time() - start_time) * 1000
        tokens = response.usage.total_tokens
        cost_usd = (tokens / 1000) * 0.00002

        metrics = get_metrics()
        metrics.add_call(tokens=tokens, latency_ms=latency_ms, cost_usd=cost_usd)

        embedding = response.data[0].embedding

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ cache
        cache.set(text, embedding)

        return embedding

    except Exception as e:
        logger.error(f"‚ùå Embedding generation failed: {e}")
        get_metrics().add_error()
        raise
```

**4.3. –î–æ–±–∞–≤–∏—Ç—å API endpoint**

```python
from bot.cache.embedding_cache import get_cache

@app.get("/api/admin/embedding/cache")
async def embedding_cache_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ embedding cache"""
    cache = get_cache()
    return {
        "status": "ok",
        "cache": cache.stats()
    }
```

**4.4. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ `.env`**

```bash
# Embedding Cache
EMBEDDING_CACHE_ENABLED=true
EMBEDDING_CACHE_SIZE=1000
EMBEDDING_CACHE_TTL=3600
```

---

### –≠—Ç–∞–ø 5: Async Parallel Processing
**–í—Ä–µ–º—è:** 1 —á–∞—Å
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü¢ LOW
**–≠—Ñ—Ñ–µ–∫—Ç:** Multi-stage search 2x –±—ã—Å—Ç—Ä–µ–µ

#### –ß—Ç–æ –¥–µ–ª–∞–µ–º:

**5.1. –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –Ω–∞ async/await**

–û–±–Ω–æ–≤–∏—Ç—å `bot/services/supabase_service.py`:

```python
async def _generate_embedding_async(self, text: str) -> List[float]:
    """Async –≤–µ—Ä—Å–∏—è –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö calls"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º asyncio.to_thread –¥–ª—è blocking OpenAI call
    import asyncio

    return await asyncio.to_thread(self._generate_embedding, text)
```

**5.2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ `knowledge_search.py`**

```python
async def _search_semantic(self, query: str, limit: int) -> List[Dict]:
    """Multi-stage search —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ embedding calls"""
    import asyncio

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ (–Ω–µ —Ç—Ä–∏!)
    query_embedding = await self.supabase_service._generate_embedding_async(query)

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏—â–µ–º –≤–æ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
    lesson_task = self.supabase_service.hybrid_search(
        query=query, entity_type="lesson", limit=limit
    )
    correction_task = self.supabase_service.hybrid_search(
        query=query, entity_type="correction", limit=limit
    )
    faq_task = self.supabase_service.hybrid_search(
        query=query, entity_type="faq", limit=limit
    )

    # –ñ–¥—ë–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    lesson_results, correction_results, faq_results = await asyncio.gather(
        lesson_task, correction_task, faq_task
    )

    # –ü—Ä–∏–º–µ–Ω—è–µ–º boosting
    for r in lesson_results:
        r['score'] *= 1.5
    for r in correction_results:
        r['score'] *= 1.2

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    all_results = lesson_results + correction_results + faq_results
    all_results.sort(key=lambda x: x['score'], reverse=True)

    return all_results[:limit]
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –î–û: 3 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö search calls = 300ms
- –ü–û–°–õ–ï: 1 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π batch = 150ms

---

### –≠—Ç–∞–ø 6: systemd Service Optimization
**–í—Ä–µ–º—è:** 30 –º–∏–Ω—É—Ç
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü¢ LOW
**–≠—Ñ—Ñ–µ–∫—Ç:** Production-ready configuration

#### –ß—Ç–æ –¥–µ–ª–∞–µ–º:

**6.1. –û–±–Ω–æ–≤–∏—Ç—å `~/.config/systemd/user/ignatova-bot.service`**

```ini
[Unit]
Description=Ignatova Stroinost Bot (Telegram + Supabase)
After=network.target ignatova-bot-ngrok.service
Requires=ignatova-bot-ngrok.service

[Service]
Type=simple
WorkingDirectory=/home/coder/projects/bot_cloning_railway/clones/ignatova-stroinost-bot
EnvironmentFile=/home/coder/projects/bot_cloning_railway/clones/ignatova-stroinost-bot/.env

# OpenAI API (–¥–ª—è embeddings)
Environment="OPENAI_API_KEY=sk-proj-..."
Environment="OPENAI_EMBEDDING_MODEL=text-embedding-3-small"

# Supabase
Environment="USE_SUPABASE=true"
Environment="SUPABASE_URL=https://..."
Environment="SUPABASE_SERVICE_KEY=..."

# Embedding Optimization
Environment="EMBEDDING_CACHE_ENABLED=true"
Environment="EMBEDDING_CACHE_SIZE=1000"
Environment="EMBEDDING_CACHE_TTL=3600"
Environment="EMBEDDING_MONITORING_ENABLED=true"

# Logging
Environment="PYTHONUNBUFFERED=1"
StandardOutput=journal
StandardError=journal

# Service
ExecStart=/usr/bin/python3 main.py
Restart=always
RestartSec=10

# Health check –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
ExecStartPost=/bin/sh -c 'while sleep 300; do curl -s http://localhost:8001/api/admin/embedding/stats | jq ".metrics"; done'

[Install]
WantedBy=default.target
```

**6.2. Health Check Endpoints**

```python
# main.py

@app.get("/health/embeddings")
async def health_embeddings():
    """Health check –¥–ª—è embedding service"""
    try:
        # –¢–µ—Å—Ç–æ–≤—ã–π embedding call
        test_text = "test"
        service = get_supabase_service()
        embedding = service._generate_embedding(test_text)

        return {
            "status": "healthy",
            "model": "text-embedding-3-small",
            "embedding_dimensions": len(embedding),
            "cache": get_cache().stats(),
            "metrics": get_metrics().summary()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }
```

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### Metrics Comparison

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ —É–ª—É—á—à–µ–Ω–∏–π | –ü–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏–π | –£–ª—É—á—à–µ–Ω–∏–µ |
|---------|--------------|-----------------|-----------|
| **–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞** | Baseline | +15-25% | Hybrid Search |
| **Search latency (single)** | 100-250ms | 100-250ms | –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π |
| **Search latency (multi-stage)** | 300ms | 150ms | **2x –±—ã—Å—Ç—Ä–µ–µ** |
| **Migration time (3,234)** | 22 –º–∏–Ω | ~5 –º–∏–Ω | **4.4x –±—ã—Å—Ç—Ä–µ–µ** |
| **–ü–æ–≤—Ç–æ—Ä–Ω—ã–µ queries** | 127ms | <1ms | **127x –±—ã—Å—Ç—Ä–µ–µ** |
| **Cache hit rate** | 0% | ~35% | –ù–æ–≤–∞—è —Ñ–∏—á–∞ |
| **OpenAI API costs** | Baseline | -30-40% | Cache savings |
| **Monitoring** | Minimal | Full metrics | Production-ready |

### Cost Analysis

**–¢–µ–∫—É—â–∏–µ costs (–¥–æ —É–ª—É—á—à–µ–Ω–∏–π):**
- Migration: $0.02 (one-time)
- 10,000 queries/month: $0.24/year
- Total: <$1/year

**–ü–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏–π (—Å caching):**
- Migration: $0.02 (one-time, –Ω–æ 4x –±—ã—Å—Ç—Ä–µ–µ)
- 10,000 queries/month: $0.15/year (cache hit 35%)
- Total: ~$0.60/year

**–≠–∫–æ–Ω–æ–º–∏—è:** $0.40/year + 4x –±—ã—Å—Ç—Ä–µ–µ –º–∏–≥—Ä–∞—Ü–∏–∏

---

## üóÇÔ∏è –§–∞–π–ª—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è/–∏–∑–º–µ–Ω–µ–Ω–∏—è

### –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã:

| –§–∞–π–ª | –†–∞–∑–º–µ—Ä | –û–ø–∏—Å–∞–Ω–∏–µ |
|------|--------|----------|
| `bot/monitoring/embedding_monitor.py` | ~150 lines | –ú–µ—Ç—Ä–∏–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ |
| `bot/cache/embedding_cache.py` | ~120 lines | LRU cache –¥–ª—è queries |
| `migrations/supabase/hybrid_search.sql` | ~80 lines | SQL function –¥–ª—è hybrid search |
| `docs/EMBEDDING_OPTIMIZATION_PLAN.md` | ~1,200 lines | –≠—Ç–æ—Ç —Ñ–∞–π–ª |

### –ò–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:

| –§–∞–π–ª | –ò–∑–º–µ–Ω–µ–Ω–∏—è | –°—Ç—Ä–æ–∫–∏ |
|------|-----------|--------|
| `bot/services/supabase_service.py` | +hybrid_search(), +monitoring, +batch, +cache | +150 |
| `bot/services/knowledge_search.py` | –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è hybrid search, async | +50 |
| `scripts/migrate_to_supabase.py` | Batch processing | +30 |
| `main.py` | +API endpoints –¥–ª—è metrics | +30 |
| `~/.config/systemd/user/ignatova-bot.service` | Environment variables | +10 |

**Total:** ~500 –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞

---

## üöÄ –ü–æ—Ä—è–¥–æ–∫ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### Quick Wins (–î–µ–Ω—å 1: 2-3 —á–∞—Å–∞):

‚úÖ **–≠—Ç–∞–ø 2: Monitoring** (1-2 —á–∞—Å–∞)
- –°–æ–∑–¥–∞—Ç—å `embedding_monitor.py`
- –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ `supabase_service.py`
- API endpoint `/api/admin/embedding/stats`

‚úÖ **–≠—Ç–∞–ø 3: Batch Processing** (1 —á–∞—Å)
- –ú–µ—Ç–æ–¥ `_generate_embeddings_batch()`
- –û–±–Ω–æ–≤–∏—Ç—å `migrate_to_supabase.py`

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** Full visibility + 4x –±—ã—Å—Ç—Ä–µ–µ –º–∏–≥—Ä–∞—Ü–∏–∏

---

### Main Features (–î–µ–Ω—å 2: 3-4 —á–∞—Å–∞):

‚úÖ **–≠—Ç–∞–ø 1: Hybrid Search** (2-3 —á–∞—Å–∞)
- SQL migration `hybrid_search.sql`
- –ú–µ—Ç–æ–¥ `hybrid_search()` –≤ `supabase_service.py`
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ `knowledge_search.py`

‚úÖ **–≠—Ç–∞–ø 4: Query Caching** (1-2 —á–∞—Å–∞)
- –°–æ–∑–¥–∞—Ç—å `embedding_cache.py`
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ `_generate_embedding()`
- API endpoint `/api/admin/embedding/cache`

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** +15-25% —Ç–æ—á–Ω–æ—Å—Ç—å + 127x –±—ã—Å—Ç—Ä–µ–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ queries

---

### Optimizations (–î–µ–Ω—å 3: 1-2 —á–∞—Å–∞, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):

‚ö†Ô∏è **–≠—Ç–∞–ø 5: Async Parallel** (1 —á–∞—Å)
- –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –Ω–∞ async/await
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ embedding calls

‚ö†Ô∏è **–≠—Ç–∞–ø 6: systemd Service** (30 –º–∏–Ω)
- –û–±–Ω–æ–≤–∏—Ç—å `.service` —Ñ–∞–π–ª
- Health check endpoints
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** 2x –±—ã—Å—Ç—Ä–µ–µ multi-stage search

---

## üìù Checklist –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### Pre-deployment:

- [ ] –°–æ–∑–¥–∞—Ç—å –≤–µ—Ç–∫—É `feature/embedding-optimization`
- [ ] Backup —Ç–µ–∫—É—â–µ–π –ë–î Supabase
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å .env –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ

### –≠—Ç–∞–ø 1 (Hybrid Search):

- [ ] –°–æ–∑–¥–∞—Ç—å `migrations/supabase/hybrid_search.sql`
- [ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é –≤ Supabase Dashboard
- [ ] –°–æ–∑–¥–∞—Ç—å GIN –∏–Ω–¥–µ–∫—Å –¥–ª—è fulltext search
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `bot/services/supabase_service.py` (+hybrid_search)
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `bot/services/knowledge_search.py` (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è)
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ

### –≠—Ç–∞–ø 2 (Monitoring):

- [ ] –°–æ–∑–¥–∞—Ç—å `bot/monitoring/embedding_monitor.py`
- [ ] –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ `supabase_service.py`
- [ ] –°–æ–∑–¥–∞—Ç—å API endpoint `/api/admin/embedding/stats`
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏

### –≠—Ç–∞–ø 3 (Batch Processing):

- [ ] –î–æ–±–∞–≤–∏—Ç—å `_generate_embeddings_batch()` –≤ `supabase_service.py`
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `scripts/migrate_to_supabase.py`
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å batch –º–∏–≥—Ä–∞—Ü–∏—é

### –≠—Ç–∞–ø 4 (Caching):

- [ ] –°–æ–∑–¥–∞—Ç—å `bot/cache/embedding_cache.py`
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `_generate_embedding()`
- [ ] –°–æ–∑–¥–∞—Ç—å API endpoint `/api/admin/embedding/cache`
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å cache hit rate

### –≠—Ç–∞–ø 5 (Async):

- [ ] –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –Ω–∞ async/await
- [ ] –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ embedding calls –≤ `knowledge_search.py`
- [ ] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å latency improvement

### –≠—Ç–∞–ø 6 (systemd):

- [ ] –û–±–Ω–æ–≤–∏—Ç—å `~/.config/systemd/user/ignatova-bot.service`
- [ ] –î–æ–±–∞–≤–∏—Ç—å health check endpoints
- [ ] Reload systemd daemon: `systemctl --user daemon-reload`
- [ ] Restart service: `systemctl --user restart ignatova-bot.service`
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏: `journalctl --user -u ignatova-bot.service -f`

### Post-deployment:

- [ ] –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ 24 —á–∞—Å–∞
- [ ] –ü—Ä–æ–≤–µ—Ä–∏—Ç—å cache hit rate
- [ ] –û–±–Ω–æ–≤–∏—Ç—å `CLAUDE.md` —Å –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
- [ ] –°–æ–∑–¥–∞—Ç—å `docs/EMBEDDING_OPTIMIZATION.md` (summary)
- [ ] Commit –≤ GitHub
- [ ] –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: Deploy –Ω–∞ Railway

---

## üîç Debugging & Troubleshooting

### –ü—Ä–æ–≤–µ—Ä–∫–∞ hybrid search:

```bash
# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
curl -X POST "http://localhost:8001/api/admin/test/hybrid_search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "–∫–∞–∫ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –º–æ–∑–≥–æ—Ä–∏—Ç–º",
    "entity_type": "lesson",
    "limit": 5
  }'
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫:

```bash
# Embedding stats
curl "http://localhost:8001/api/admin/embedding/stats" | jq

# Cache stats
curl "http://localhost:8001/api/admin/embedding/cache" | jq

# Health check
curl "http://localhost:8001/health/embeddings" | jq
```

### systemd –ª–æ–≥–∏:

```bash
# –í—Å–µ –ª–æ–≥–∏
journalctl --user -u ignatova-bot.service -f

# –¢–æ–ª—å–∫–æ embedding –º–µ—Ç—Ä–∏–∫–∏
journalctl --user -u ignatova-bot.service -f | grep "OpenAI embedding"

# Summary stats
journalctl --user -u ignatova-bot.service -f | grep "Embedding Session Stats"
```

---

## üí° Future Enhancements (–Ω–µ –≤ —ç—Ç–æ–º –ø–ª–∞–Ω–µ)

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:

1. **Cohere Reranking** (+10-15% —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ $1/1K requests)
2. **Redis persistent cache** (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É restarts)
3. **Prometheus metrics** (–¥–ª—è Grafana dashboards)
4. **A/B testing framework** (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ hybrid vs semantic)
5. **Adaptive semantic/fulltext weights** (ML-based optimization)
6. **Query intent classification** (–∞–≤—Ç–æ–≤—ã–±–æ—Ä semantic_weight/fulltext_weight)

### Advanced features:

7. **Multi-language support** (—Ä—É—Å—Å–∫–∏–π + –∞–Ω–≥–ª–∏–π—Å–∫–∏–π tsvector)
8. **Phrase boosting** ("–º–æ–∑–≥–æ—Ä–∏—Ç–º" ‚Üí higher weight)
9. **Entity-specific weights** (lessons vs corrections —Ä–∞–∑–Ω—ã–µ –≤–µ—Å–∞)
10. **User feedback loop** (—É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∏–∫–æ–≤)

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:

- **awesome-llm-apps:** https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials
- **OpenAI Embeddings:** https://platform.openai.com/docs/guides/embeddings
- **Supabase Vector:** https://supabase.com/docs/guides/ai/vector-columns
- **pgvector:** https://github.com/pgvector/pgvector
- **PostgreSQL FTS:** https://www.postgresql.org/docs/current/textsearch.html

### –ò–Ω—Å–ø–∏—Ä–∞—Ü–∏—è –∏–∑ awesome-llm-apps:

- **Agentic RAG GPT-5:** Agno framework, LanceDB, streaming
- **Corrective RAG:** Self-grading, query transformation, web fallback
- **Hybrid Search RAG:** Semantic + Keyword + BM25 + Reranking

### –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (reference):

- **–°—É–º–º–∞—Ä–Ω–æ entities:** 3,234 (FAQ: 25, Lessons: 127, Corrections: 275, Questions: 2,635, Brainwrites: 172)
- **Embedding model:** text-embedding-3-small (1536D)
- **Vector DB:** Supabase (PostgreSQL + pgvector)
- **–ú–∏–≥—Ä–∞—Ü–∏—è cost:** $0.02 (992,051 tokens)
- **–ú–∏–≥—Ä–∞—Ü–∏—è time:** 22 –º–∏–Ω—É—Ç—ã

---

**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–ª–∞–Ω –≥–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
**–î–∞—Ç–∞:** 18 –Ω–æ—è–±—Ä—è 2025
**–ê–≤—Ç–æ—Ä:** Claude Code
**–í–µ—Ä—Å–∏—è:** 1.0
