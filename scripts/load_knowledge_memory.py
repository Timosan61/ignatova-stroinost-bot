#!/usr/bin/env python3
"""
–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –∑–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ Memory API –≤–º–µ—Å—Ç–æ Knowledge Graph.
–°–æ–∑–¥–∞—ë–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –¥–∏–∞–ª–æ–≥–∏ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∑–Ω–∞–Ω–∏–π.
"""

import os
import re
import asyncio
import logging
from typing import List, Dict, Any
from datetime import datetime
from dataclasses import dataclass

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from zep_cloud.client import AsyncZep
from zep_cloud.types import Message

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class KnowledgeChunk:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —á–∞–Ω–∫–∞ –∑–Ω–∞–Ω–∏–π"""
    content: str
    title: str
    category: str
    source: str
    metadata: Dict[str, Any]

class KnowledgeMemoryLoader:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ Zep Memory –∫–∞–∫ –¥–∏–∞–ª–æ–≥–∏"""
    
    def __init__(self, zep_api_key: str):
        self.zep_client = AsyncZep(api_key=zep_api_key)
        
    def split_markdown_by_sections(self, content: str) -> List[KnowledgeChunk]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç markdown —Ñ–∞–π–ª –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏ –ø–æ —Å–µ–∫—Ü–∏—è–º"""
        chunks = []
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –≥–ª–∞–≤–Ω—ã–º —Å–µ–∫—Ü–∏—è–º (## –∑–∞–≥–æ–ª–æ–≤–∫–∏)
        main_sections = re.split(r'\n(?=## )', content)
        
        for section in main_sections:
            if not section.strip():
                continue
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–µ–∫—Ü–∏–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            chunk = self._process_section(section)
            if chunk:
                chunks.append(chunk)
        
        logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
        return chunks
    
    def _process_section(self, section: str) -> KnowledgeChunk:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Å–µ–∫—Ü–∏—é –∏ —Å–æ–∑–¥–∞—ë—Ç —á–∞–Ω–∫"""
        lines = section.strip().split('\n')
        
        if not lines:
            return None
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
        title = lines[0].strip('# ').strip()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        category = self._determine_category(section)
        source = self._extract_source(section)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ 1500 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è Memory)
        max_chars = 1500
        content = section
        if len(content) > max_chars:
            # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–º—ã—Å–ª
            sentences = re.split(r'(?<=[.!?])\s+', content)
            truncated = ""
            for sentence in sentences:
                if len(truncated + sentence) > max_chars:
                    break
                truncated += sentence + " "
            content = truncated.strip()
        
        # –°–æ–∑–¥–∞—ë–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'word_count': len(content.split()),
            'char_count': len(content),
            'created_at': datetime.now().isoformat(),
            'contains_scripts': '—Å–∫—Ä–∏–ø—Ç' in content.lower() or '—à–∞–±–ª–æ–Ω' in content.lower(),
            'contains_objections': '–≤–æ–∑—Ä–∞–∂–µ–Ω–∏' in content.lower(),
            'contains_faq': 'FAQ' in section or '–≤–æ–ø—Ä–æ—Å' in content.lower(),
        }
        
        return KnowledgeChunk(
            content=content,
            title=title,
            category=category,
            source=source,
            metadata=metadata
        )
    
    def _determine_category(self, section: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —á–∞–Ω–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É"""
        section_lower = section.lower()
        
        if 'call_' in section_lower and 'summary' in section_lower:
            return 'training_summary'
        elif 'call_' in section_lower and 'faq' in section_lower:
            return 'training_faq'
        elif '—Å–∫—Ä–∏–ø—Ç' in section_lower or '—à–∞–±–ª–æ–Ω' in section_lower:
            return 'scripts'
        elif '–≤–æ–∑—Ä–∞–∂–µ–Ω–∏' in section_lower:
            return 'objections'
        elif 'faq' in section_lower or '–≤–æ–ø—Ä–æ—Å' in section_lower:
            return 'faq'
        elif '—Ç–µ—Ö–Ω–∏–∫' in section_lower or '–º–µ—Ç–æ–¥' in section_lower:
            return 'techniques'
        elif '–ø—Ä–æ–¥–∞–∂' in section_lower or '–ø—Ä–æ–¥–∞–≤' in section_lower:
            return 'sales_methodology'
        else:
            return 'general'
    
    def _extract_source(self, section: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ (–Ω–æ–º–µ—Ä call'–∞) –∏–∑ —Å–µ–∫—Ü–∏–∏"""
        match = re.search(r'call_(\d+)', section)
        if match:
            return f"call_{match.group(1)}"
        return "general"
    
    async def upload_to_zep_memory(self, chunks: List[KnowledgeChunk]) -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–∞–Ω–∫–∏ –≤ Zep Memory –∫–∞–∫ –¥–∏–∞–ª–æ–≥–∏"""
        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É {len(chunks)} —á–∞–Ω–∫–æ–≤ –≤ Zep Memory...")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ—Å—Å–∏–π
            categories = {}
            for chunk in chunks:
                if chunk.category not in categories:
                    categories[chunk.category] = []
                categories[chunk.category].append(chunk)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é, —Ä–∞–∑–±–∏–≤–∞—è –Ω–∞ –ø–æ–¥—Å–µ—Å—Å–∏–∏ –ø–æ 12 —á–∞–Ω–∫–æ–≤ (24 —Å–æ–æ–±—â–µ–Ω–∏—è + —Å–∏—Å—Ç–µ–º–∞ = 25 < 30)
            total_loaded = 0
            max_chunks_per_session = 12
            
            for category, category_chunks in categories.items():
                try:
                    # –†–∞–∑–±–∏–≤–∞–µ–º –±–æ–ª—å—à–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ –ø–æ–¥—Å–µ—Å—Å–∏–∏
                    chunk_batches = [category_chunks[i:i + max_chunks_per_session] 
                                   for i in range(0, len(category_chunks), max_chunks_per_session)]
                    
                    for batch_idx, batch_chunks in enumerate(chunk_batches):
                        try:
                            session_id = f"knowledge_{category}_session_{batch_idx + 1}"
                            
                            # –°–æ–∑–¥–∞—ë–º –¥–∏–∞–ª–æ–≥ –¥–ª—è —ç—Ç–æ–π –ø–æ–¥—Å–µ—Å—Å–∏–∏
                            messages = []
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å—Ç—É–ø–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                            intro_message = Message(
                                role="system",
                                role_type="system",
                                content=f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π [{category.upper()}] —á–∞—Å—Ç—å {batch_idx + 1}. –ß–∞–Ω–∫–æ–≤ –≤ —ç—Ç–æ–π —á–∞—Å—Ç–∏: {len(batch_chunks)}"
                            )
                            messages.append(intro_message)
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫ –∫–∞–∫ –ø–∞—Ä—É –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
                            for chunk in batch_chunks:
                                # –°–æ–∑–¥–∞—ë–º –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                                question_content = f"–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ: {chunk.title}"
                                question = Message(
                                    role="user",
                                    role_type="user", 
                                    content=question_content
                                )
                                
                                # –°–æ–∑–¥–∞—ë–º –æ—Ç–≤–µ—Ç —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —á–∞–Ω–∫–∞
                                answer_content = f"[{chunk.category.upper()}] {chunk.title}\n\n{chunk.content}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {chunk.source}"
                                answer = Message(
                                    role="assistant",
                                    role_type="assistant",
                                    content=answer_content
                                )
                                
                                messages.extend([question, answer])
                            
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–¥—Å–µ—Å—Å–∏—é
                            await self.zep_client.memory.add(session_id=session_id, messages=messages)
                            
                            total_loaded += len(batch_chunks)
                            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ø–æ–¥—Å–µ—Å—Å–∏—è '{category}' —á–∞—Å—Ç—å {batch_idx + 1}: {len(batch_chunks)} —á–∞–Ω–∫–æ–≤")
                            
                            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–¥—Å–µ—Å—Å–∏—è–º–∏
                            await asyncio.sleep(0.2)
                        
                        except Exception as e:
                            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–¥—Å–µ—Å—Å–∏–∏ '{category}' —á–∞—Å—Ç—å {batch_idx + 1}: {e}")
                            continue
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {e}")
                    continue
            
            logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_loaded} —á–∞–Ω–∫–æ–≤ –≤ Zep Memory")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Zep Memory: {e}")
            return False
    
    async def test_memory_search(self, query: str, limit: int = 3) -> List[str]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        try:
            # –ò—â–µ–º –ø–æ –≤—Å–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∑–Ω–∞–Ω–∏–π –≤–∫–ª—é—á–∞—è –ø–æ–¥—Å–µ—Å—Å–∏–∏
            results = []
            
            categories = [
                'training_summary', 'training_faq', 'scripts', 'objections', 
                'faq', 'techniques', 'sales_methodology', 'general'
            ]
            
            for category in categories:
                # –ò—â–µ–º –≤–æ –≤—Å–µ—Ö –ø–æ–¥—Å–µ—Å—Å–∏—è—Ö —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                for session_part in range(1, 20):  # –ú–∞–∫—Å–∏–º—É–º 20 –ø–æ–¥—Å–µ—Å—Å–∏–π –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                    try:
                        session_id = f"knowledge_{category}_session_{session_part}"
                        memory = await self.zep_client.memory.search(
                            session_id=session_id,
                            query=query,
                            limit=2  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –ø–æ–¥—Å–µ—Å—Å–∏–∏
                        )
                        
                        if memory and hasattr(memory, 'results') and memory.results:
                            for result in memory.results[:2]:  # –ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                                if hasattr(result, 'message') and result.message:
                                    results.append(result.message.content)
                                elif hasattr(result, 'content'):
                                    results.append(result.content)
                        
                    except Exception as e:
                        # –ï—Å–ª–∏ —Å–µ—Å—Å–∏–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø–æ–∏—Å–∫ –ø–æ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        if "404" in str(e):
                            break
                        logger.debug(f"–ü–æ–∏—Å–∫ –≤ –ø–æ–¥—Å–µ—Å—Å–∏–∏ {session_id} –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
                        continue
            
            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
            return results[:limit]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –ø–∞–º—è—Ç–∏: {e}")
            return []

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
    zep_api_key = os.getenv('ZEP_API_KEY')
    if not zep_api_key:
        logger.error("‚ùå ZEP_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
        return
    
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π
    knowledge_file = os.path.join(
        os.path.dirname(os.path.dirname(__file__)), 
        'Sales_Assistant_Master_Instruction_CONTENT_ONLY.md'
    )
    
    if not os.path.exists(knowledge_file):
        logger.error(f"‚ùå –§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {knowledge_file}")
        return
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    logger.info(f"üìñ –ß–∏—Ç–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏–∑ {knowledge_file}")
    with open(knowledge_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    logger.info(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°–æ–∑–¥–∞—ë–º –∑–∞–≥—Ä—É–∑—á–∏–∫
    loader = KnowledgeMemoryLoader(zep_api_key)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
    chunks = loader.split_markdown_by_sections(content)
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    logger.info(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤:")
    categories = {}
    for chunk in chunks:
        categories[chunk.category] = categories.get(chunk.category, 0) + 1
    
    for category, count in categories.items():
        logger.info(f"  {category}: {count} —á–∞–Ω–∫–æ–≤")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Zep Memory
    success = await loader.upload_to_zep_memory(chunks)
    
    if success:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        logger.info("\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –≤ –ø–∞–º—è—Ç–∏...")
        
        test_queries = [
            "–∫–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏",
            "—Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã",
            "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Å–∏—Ö–æ—Ç–∏–ø–∞",
            "–º–∞—Ä–∞—Ñ–æ–Ω—ã –ø–æ—Ö—É–¥–µ–Ω–∏—è —Ü–µ–Ω–∞"
        ]
        
        for query in test_queries:
            results = await loader.test_memory_search(query, limit=2)
            logger.info(f"  '{query}': {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            if results:
                logger.info(f"    –ü—Ä–µ–≤—å—é: {results[0][:100]}...")

if __name__ == "__main__":
    asyncio.run(main())